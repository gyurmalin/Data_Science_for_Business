---
title: "Data Science for Business: Homework Assignment"
author: "Gyorgy Jablonszky"
date: "February 28, 2016"
output: html_document
fontsize: 14p
---

******



### **Bank Marketing Data Set**


#### Downloaded from UCI Machine Learning Repository

******
#### Source: http://archive.ics.uci.edu/ml/datasets/Bank+Marketing.

#### This dataset is public available for research. The details are described in S. Moro, P. Cortez and P. Rita. A Data-Driven Approach to Predict the Success of Bank Telemarketing. Decision Support Systems, Elsevier, 62:22-31, June 2014

******

### Introduction

This dataset provides unformation of telemarketing campaigns pursued by a Portuguese bank. Aim of current analysis is to predict whether a client would subscribe for a term deposit (yes/no). There are 20 input variables and a binary output variable.

**For this assignment I decided to mark all code chunks in the documentation in order to track processes step-by-step.**

******

#### Set libraries



```{r warning=FALSE, error=FALSE, message=FALSE}
library(readr)
library(dplyr)
library(reshape2)
library(ggplot2)
library(pander)
library(h2o)

library(knitr)
opts_knit$set(root.dir = "../")

```

******

### Read data and review data structure


```{r}
bank <- read.csv("C:/Users/Szaffi/Desktop/Gyurma/Data_Science_for_Business/bank-additional/bank-additional-full.csv", sep=";") # specify directory or URL as data soruce
```

I decided to randomly reorder data at this early stage

```{r}
bank <- bank[sample(1:nrow(bank)), ]
```

Our variables are the following (with the outpur variable *y* at the 21th place):

```{r}
colnames(bank)
```

Let's have a look at the structure of our data. We have 20 predictors and 1 output variable and altogether 41188 observations.

```{r}
dim(bank)
str(bank)
```

It may be useful to prepare some very basic descriptive statistics at this early stage of the data analysis project on raw data set. As one can see below there are categories like 'unknownn' and 'other' at many variables. We keep it in mind for later steps.

```{r}
pander(summary(bank))
```

******

#### Now, let's have a quick look at data itself checking the first 3 elements of each features

```{r}
pander(head(bank, 3))
```

******

#### Check NAs and less than 0 values

```{r warning=FALSE}
sapply(bank, function(x) sum(is.na(x)))
sapply(bank, function(x) sum(x<0, na.rm=TRUE)) 
```

As we will see later there are some variables with 'unknown' values (not equal to NAs).
There are two variables with negative values by default (*emp.var.rate and cons.conf_idx*).

*******

*******

### Variables in data set

*******

####  **Target variable: Y** (*binary: 'Yes' / 'No'*)

This variables shows whether the customer subscribed for a term deposit. 

```{r}
pander(bank %>% group_by(y) %>% summarize(n = n()) %>% mutate(percentage = n/sum(n)*100))
```

More than 11% of customers subscribed for term deposit that altogether means 4640 observations.

*******

#### Input variables - predictors


##### **Age** (*numeric*)

This variable provides information on customer's age in years

```{r}
pander(summary(bank$age))
ggplot(bank, aes(x = age)) + geom_histogram(binwidth = 5, col = "white") + theme_bw()
```

An important question whether to exclude observations under or above a specified treshold.
We have 5 observations with an age below 18 years and 10 with higher than 90. I decided to exclude these rows according to relatively high probability of data error. 

```{r}
nrow(bank[bank$age < 18, ])
nrow(bank[bank$age > 90, ])

bank <- bank %>% filter(age >= 18)
bank <- bank %>% filter(age < 90)
dim(bank)
```


As age variable shows a slightly skewed distribution with a right tail I decided to try taking logs and check distibution of log values as well.

```{r}
bank$lnage <- log(bank$age)
pander(summary(bank$lnage))
ggplot(bank, aes(x = lnage)) + geom_histogram(binwidth = 0.1, col = "white") + theme_bw()
```

Let's have a look at ages by the target variable:

```{r}
ggplot(bank) + geom_histogram(aes(x = age), binwidth = 0.1, col = "white") +
  facet_grid(y~., scales = "free") + scale_x_log10() + theme_bw()
```


*****

##### **Job** (*categorical*)

Job variable gives information on the job profile of targeted customers. There are 11 specified and 1 unspecified categories.

```{r}
ggplot(bank, aes(x = job)) + geom_bar() + theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
nrow(bank[bank$job =="unknown", ])
```

All observations are listed under the 12 categories with 330 unknown. In order to enhance accuracy finally I decided to exclude observations with unknown job category.

```{r}
bank <- bank %>% filter(job != "unknown") 
```

```{r}
ggplot(bank) + geom_bar(aes(x = job), col = "white") +
  facet_grid(y~., scales = "free")  + theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

*****

##### **Marital** (*categorical*)

Marital status feature contains 4 categories as follows:

```{r}
ggplot(bank, aes(x = marital)) + geom_bar() + theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
nrow(bank[bank$marital =="unknown", ])
```

There are 80 variables with unknown marital status: considering the small number of observations I decided to exclude all these records.

```{r}
bank <- bank %>% filter(marital != "unknown") 
```

```{r}
ggplot(bank) + geom_bar(aes(x = marital), col = "white") +
  facet_grid(y~., scales = "free")  + theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

*****

##### **Education** (*categorical*)

Education is also a categorical variable with 7 categories + 1 unknown.

```{r}
ggplot(bank, aes(x = education)) + geom_bar() + theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
nrow(bank[bank$education =="unknown", ])
nrow(bank[bank$education =="illiterate", ])
```

In case of education variable number of unknkown observations is pretty high.
In order to decide whether to exclude them let's check education by our target variable.

By eyeballing I decide now not to exclude observations concerned as their ratio ssems to be similar in both cases of decisions.

On the other hand I decided to exclude those 18 observations that are listed in the illiteral category.

```{r}
ggplot(bank) + geom_bar(aes(x = education), col = "white") +
  facet_grid(y~., scales = "free")  + theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

```{r}
bank <- bank %>% filter(education != "illiterate") 

```


*****

##### **Default** (*categorical*)

This variable shows whether the targeted customer has a credit in default.
There are 3 categories: a binary yes/no and the unknown  that seems to be an issue as about 20% of customers are in the latter category.

```{r}
nrow(bank[bank$default =="unknown", ])
```

```{r}
ggplot(bank, aes(x = default)) + geom_bar() + theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
ggplot(bank) + geom_bar(aes(x = default), col = "white") +
  facet_grid(y~., scales = "free")  + theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

```{r}
nrow(bank[bank$default =="yes", ])
```

As number of obsevations with yes is negligable I suppose that its an exclusion to have a credit in default. 3 exceptions are probably errors that will be excluded. Unknown observations, however, will not be excluded due to their relatively high proportion.

```{r}
bank <- bank %>% filter(default != "yes") 

```

*****

##### **Housing** (*categorical*)

This variable shows whether the targeted customer has a housing loan.
Here we also have 3 categories: a binary yes/no and the unknown.

```{r}
ggplot(bank, aes(x = housing)) + geom_bar() + theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
ggplot(bank) + geom_bar(aes(x = housing), col = "white") +
  facet_grid(y~., scales = "free")  + theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

Let's remove unknown.

```{r}
bank <- bank %>% filter(housing != "unknown") 

```


*****

##### **Loan** (*categorical*)

Whether the targeted customer has a personal loan (yes/no/unknown).

```{r}
ggplot(bank, aes(x = loan)) + geom_bar() + theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
ggplot(bank) + geom_bar(aes(x = loan), col = "white") +
  facet_grid(y~., scales = "free")  + theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

Let's remove unknown again.

```{r}
bank <- bank %>% filter(loan != "unknown") 

```

*****

##### **Contact** (*categorical*)

This variable shows the contact communication type (cellular/telephone).

```{r}
ggplot(bank, aes(x = contact)) + geom_bar() + theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
ggplot(bank) + geom_bar(aes(x = contact), col = "white") +
  facet_grid(y~., scales = "free")  + theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
```


*****

##### **Month** (*categorical*)

Last contact month of the year (cellular/telephone).

Order of months looks a bit strange, I admit. But it's OK now for us (checking variables).
Contact month seems to be a strong predictor - at least for current dataset. Keep it in mind (in order to avoid overfitting later).
```{r}
ggplot(bank, aes(x = month)) + geom_bar() + theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
ggplot(bank) + geom_bar(aes(x = month), col = "white") +
  facet_grid(y~., scales = "free")  + theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

*****

##### **Day of week** (*categorical*)

Last contact day of the week (the 5 weekdays). Nothing special at first sight.

```{r}
ggplot(bank, aes(x = day_of_week)) + geom_bar() + theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
ggplot(bank) + geom_bar(aes(x = day_of_week), col = "white") +
  facet_grid(y~., scales = "free")  + theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
```


*****

##### **Duration** (*numeric*)

Last contact duration, in seconds. 
*Authors note: "this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model."*

Based on above I'm going to exclude this variable, however, it's worth to see its distribution in itself.

```{r}
ggplot(bank, aes(x = duration)) + geom_bar() + theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
ln_duration <- log(bank$duration)
ggplot(bank, aes(x = ln_duration)) + geom_histogram(binwidth = 0.1) + theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
ggplot(bank) + geom_histogram(aes(x = ln_duration), binwidth = 0.1) +
  facet_grid(y~., scales = "free")  + theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

*****

##### **Campaign** (*numeric*)

Number of contacts performed during this campaign and for this client (including last contact).
Campaign lasts for 10 months. I consider more than 10 contacts an issue or data error (vecause of probably applied contact rules). We have 0.8k observations with more than 10 contacts. I'm going to drop them as possible errors.

```{r}
summary(bank$campaign)
ggplot(bank, aes(x = campaign)) + geom_histogram(binwidth = 1) + theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
nrow(bank[bank$campaign > 10, ])
bank <- bank %>% filter(campaign < 10) 
```


*****

##### **Pdays** (*numeric*)

Number of days after the client was last contacted from a previous campaign (999 means client was not previously contacted). In most cases this variable gets 999 that's why I won't use it as a predictor.

```{r}
ggplot(bank, aes(x = pdays)) + geom_histogram(binwidth = 50) + theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
```


*****

##### **Previous** (*numeric*)

Number of contacts performed before this campaign and for this client. Seems to be a good predictor as customers may change their view as get used to be contacted.


```{r}
ggplot(bank, aes(x = previous)) + geom_histogram(binwidth = 1) + theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
ggplot(bank) + geom_histogram(aes(x = previous), binwidth = 1) +
  facet_grid(y~., scales = "free")  + theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
```


*****

##### **Poutcome** (*categorical*)

This feature shows the outcome of the previous marketing campaign. Possible categories are the following: failure/nonexistent/success. As we can see by eyballing previous success shows a probable affinity for such campaigns, however, sample was too small to draw far-reaching conclusions. 

```{r}
ggplot(bank, aes(x = poutcome)) + geom_bar() + theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
ggplot(bank) + geom_bar(aes(x = poutcome), col = "white") +
  facet_grid(y~., scales = "free")  + theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

*****

##### **Emp.var.rate** (*numeric*)

Employment variation rate (quarterly). To be honest, I'm not so familiar with this indicator. Let's have a look at it. Wow! We have negative values. So, according to Google search, I found that it's a kind of macroeconomic indicator that's related to the contact date (with quartely data collection). I'm not sure it will be relevant for us, but we'll see. Some relationship, however, is presumable with the contact date.

```{r}
ggplot(bank, aes(x = emp.var.rate)) + geom_histogram(binwidth = 1) + theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

*****

##### **Cons.price.idx** (*numeric*)

Consumer price index, also a macro indicator, collected on monthly basis. 

```{r}
ggplot(bank, aes(x = cons.price.idx)) + geom_histogram(binwidth = 1) + theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
ggplot(bank) + geom_histogram(aes(x = cons.price.idx), binwidth = 1) +
  facet_grid(y~., scales = "free")  + theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

*****

##### **Cons.conf.idx** (*numeric*)

Consumer confidence index, also a macro indicator, collected on monthly basis (also with some values that are smaller than 0) 

```{r}
ggplot(bank, aes(x = cons.conf.idx)) + geom_histogram(binwidth = 5) + theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

*****

##### **euribor3m** (*numeric*)

euribor3m: 3m Euro Interbank Offered Rates (based on avg. interest rates) on a daily basis.

```{r}
ggplot(bank, aes(x = euribor3m)) + geom_histogram(binwidth = 0.01) + theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
```


*****

##### **Nr.employed** (*numeric*)

Number of employees collected on a quarterly base.

```{r}
ggplot(bank, aes(x = nr.employed)) + geom_histogram(binwidth = 100) + theme_bw() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
```


*****

After above modifications we have 38717 observations (excluded 2471).

```{r}
dim(bank)
```


#### Data cleaning and feature engineering

Data cleaning was performed above, here comes some new features derived from the feature set shown previously and some to drop out of our prediction.

*****

##### A new feature: age group

I decided to group observations by age groups. I assigned 3 new variables for age groups below 30 years, between 31 and 60 years and above 60.


```{r}
bank$age_1 <- as.numeric(bank$age < 30)
bank$age_2 <- as.numeric(bank$age >= 30 & bank$age <= 60)
bank$age_3 <- as.numeric(bank$age > 60)
```

*****

##### New variables: numeric values for categorical variables


In order to provide available all categorical variables for the modeling stage I also decided to add some new variables.

*****

###### For Job categories

```{r}
bank$job_1 <- as.numeric(bank$job == "admin")
bank$job_2 <- as.numeric(bank$job == "blue_collar")
bank$job_3 <- as.numeric(bank$job == "entrepreneur")
bank$job_4 <- as.numeric(bank$job == "housemaid")
bank$job_5 <- as.numeric(bank$job == "management")
bank$job_6 <- as.numeric(bank$job == "retired")
bank$job_7 <- as.numeric(bank$job == "self-employed")
bank$job_8 <- as.numeric(bank$job == "services")
bank$job_9 <- as.numeric(bank$job == "student")
bank$job_10 <- as.numeric(bank$job == "technician")
bank$job_11 <- as.numeric(bank$job == "unemployed")
```

*****

###### For Marital status

```{r}
bank$marital_1 <- as.numeric(bank$marital == "single")
bank$marital_2 <- as.numeric(bank$marital == "married")
bank$marital_3 <- as.numeric(bank$marital == "divorced")
```

*****

###### For Education

```{r}
bank$edu_1 <- as.numeric(bank$education == "basic.4y")
bank$edu_2 <- as.numeric(bank$education == "basic.6y")
bank$edu_3 <- as.numeric(bank$education == "basic.9y")
bank$edu_4 <- as.numeric(bank$education == "high.school")
bank$edu_5 <- as.numeric(bank$education == "professional.course")
bank$edu_6 <- as.numeric(bank$education == "university.degree")
bank$edu_7 <- as.numeric(bank$education == "unknown")
```

*****

###### For Default

```{r}
bank$default_1 <- as.numeric(bank$default == "no")
bank$default_2 <- as.numeric(bank$default == "unknown")
```

*****

###### For Housing

```{r}
bank$housing_1 <- as.numeric(bank$housing == "no")
bank$housing_2 <- as.numeric(bank$housing == "yes")
```

*****

###### For Loan

```{r}
bank$loan_1 <- as.numeric(bank$loan == "no")
bank$loan_2 <- as.numeric(bank$loan == "yes")
```

*****

###### For Contact

```{r}
bank$con_1 <- as.numeric(bank$contact == "cellular")
bank$con_2 <- as.numeric(bank$contact == "telephone")
```

*****

###### For Month

```{r}
bank$mar <- as.numeric(bank$month == "mar")
bank$apr <- as.numeric(bank$month  == "apr")
bank$may <- as.numeric(bank$month  == "may")
bank$jun <- as.numeric(bank$month  == "jun")
bank$jul <- as.numeric(bank$month  == "jul")
bank$aug <- as.numeric(bank$month  == "aug")
bank$sep <- as.numeric(bank$month  == "sep")
bank$oct <- as.numeric(bank$month  == "oct")
bank$nov <- as.numeric(bank$month  == "nov")
bank$dec <- as.numeric(bank$month  == "dec")
```

*****

###### For Day of week

```{r}
bank$mon <- as.numeric(bank$day_of_week == "mon")
bank$tue <- as.numeric(bank$day_of_week  == "tue")
bank$wed <- as.numeric(bank$day_of_week  == "wed")
bank$thu <- as.numeric(bank$day_of_week  == "thu")
bank$fri <- as.numeric(bank$day_of_week  == "fri")
```

*****

###### For Poutcome

```{r}
bank$poutcome1  <- as.numeric(bank$poutcome == "failure")
bank$poutcome2  <- as.numeric(bank$poutcome == "nonexistent")
bank$poutcome3  <- as.numeric(bank$poutcome == "success")
```

*****

#### Some modicitaions of feature names

```{r}
bank <- bank %>% rename(empvarrate = `emp.var.rate`, conspriceidx  = `cons.price.idx`, consconfidx  = `cons.conf.idx`, nremployed  = `nr.employed`)
```

*****

#### Drop some features

Now we have several features and some of them are overrepresented due to the dummification. There are also some features that seem to be not so good preictors or simply irrelevant as they are. So let's drop out, which we don't want to use at the modeling phase.

```{r}
bank$job <- NULL # Drop originals od dummified categorical features 
bank$marital <- NULL
bank$education <- NULL
bank$default <- NULL
bank$housing <- NULL
bank$loan <- NULL
bank$contact <- NULL
bank$month <- NULL
bank$day_of_week <- NULL
bank$poutcome <- NULL


bank$duration <- NULL
bank$pdays <- NULL

bank$empvarrate <- NULL
bank$conspriceidx <- NULL
bank$consconfidx <- NULL
bank$euribor3m <- NULL
bank$nremployed <- NULL

bank <- bank[,c(4,1,2,3,5:55)] #Reorder variables to put target variable to the first place

```

*****

After such steps we get many new variables containing binary values and some droped.

```{r}
colnames(bank)
dim(bank)
```


*****

#### Split sample

Here I'm going to split the entire sample into training/validation/test sets and also provide possibilites for cross-validation.

```{r}
set.seed(41)

N <- nrow(bank)
idx_train <- sample(1:N,N/2)
idx_valid <- sample(base::setdiff(1:N, idx_train), N/4)
idx_test <- base::setdiff(base::setdiff(1:N, idx_train),idx_valid)
bank_train <- bank[idx_train,]
bank_valid <- bank[idx_valid,]
bank_test  <- bank[idx_test,]
```

*****

### Modeling

In the following part I'm going to train and evaluate some models.
In order to enhance effifiency I used the remote H2O server for calculations.
Here my objective is to understand the modeling process in H2O. This means accuracy is a secondary consideration in this case so results will probably not be as good as they would be required in a real-life project. Thus I will not modify parameters to get the best results but run some type of models in H2O.

*****

#### Setup H2O

```{r}
library(h2o)
h2o.init(max_mem_size = "4g", nthreads = -1)
```

*****

#### Upload sets to H2O

```{r}
b_train <- as.h2o(bank_train)  
b_valid <- as.h2o(bank_valid)
b_test <- as.h2o(bank_test)
```

*****

#### Run a Random Forest model

```{r}
system.time({
  rf <- h2o.randomForest(x = 2:ncol(b_train), y = 1, 
                         seed = 41 ,training_frame = b_train, validation_frame=b_valid,
                         mtries = -1, ntrees = 500, max_depth = 20, nbins = 200)
})
```

Let's see the results. Not so dazzling, to be honest. What about GBM?

```{r}
rf

h2o.auc(rf) 
h2o.auc(h2o.performance(rf, b_test))
```

```{r}
mse <- h2o.mse(rf,train=TRUE,valid=TRUE)
print(mse)
err <- eval(rf,b_train,b_valid) 
print(err)
```

#### Run a GBM model

```{r}
system.time({
  gbm <- h2o.gbm(x = 2:ncol(b_train), y = 1, 
                seed = 41, training_frame = b_train, validation_frame = b_valid,
                max_depth = 15, ntrees = 500, learn_rate = 0.03, nbins = 100,
                stopping_rounds = 3)
})
```

Now, the results. Could be better if parameter were changed.

```{r}
gbm

h2o.auc(gbm)
h2o.auc(h2o.performance(gbm, b_test))
```

```{r}
gbm_mse <- h2o.mse(gbm,train=TRUE,valid=TRUE)
print(gbm_mse)
gbm_err <- eval(gbm,b_train,b_valid)
print(gbm_err)
```

#### Now run a GBM model with x-validation

```{r}
system.time({
  gbmx <- h2o.gbm(x = 2:ncol(b_train), y = 1, 
                seed = 41, training_frame = b_train, validation_frame = b_valid,
                max_depth = 15, ntrees = 500, learn_rate = 0.03, nbins = 100, nfolds = 5,
                stopping_rounds = 3)
})
```

```{r}
gbmx

h2o.auc(gbmx)
h2o.auc(h2o.performance(gbmx, b_test))
```

```{r}
gbmx_mse <- h2o.mse(gbmx,train=TRUE,valid=TRUE)
print(gbmx_mse)
gbmx_err <- eval(gbmx,b_train,b_valid)
print(gbmx_err)
```

#### Now a GBM model with grid-search 

*This GBM Grid Search was finally excluded from the project by reason of a technical issue:

I could not manage to run it in rmd without getting the following error message:*

*-Quitting from lines 832-836 (DS_HA.rmd) 
Error in .h2o.doSafeREST(h2oRestApiVersion = h2oRestApiVersion, urlSuffix = page,  : 
  Unexpected CURL error: Recv failure: Connection was reset
Calls: <Anonymous> ... h2o.getModel -> .h2o.__remoteSend -> .h2o.doSafeREST
In addition: There were 19 warnings (use warnings() to see them)*-

Code, however, is provided below:
<!--

system.time({
  gbmgr <- h2o.grid("gbm", x = 2:ncol(b_train), y = 1, 
            training_frame = b_train, validation_frame = b_valid,
            hyper_params = list(ntrees = 500,
                                max_depth = c(5,10,20),
                                learn_rate = c(0.01,0.1),
                                nbins = 100),
            stopping_rounds = 5)
})



gbmgr

do.call(rbind, lapply(gbmgr@model_ids, function(m_id) {
  mm <- h2o.getModel(m_id)
  hyper_params <- mm@allparameters
  data.frame(m_id = m_id, 
             auc = h2o.performance(mm, b_test)@metrics$AUC,
             max_depth = hyper_params$max_depth,
             learn_rate = hyper_params$learn_rate )
})) %>% arrange(desc(auc)) 



gbmgr_mse <- h2o.mse(gbmgr,train=TRUE,valid=TRUE)
print(gbmgr_mse)
gbmgr_err <- eval(gbmgr,b_train,b_valid)
print(gbmgr_err)

-->

#### Finally, a Neural Network

```{r}
system.time({
  nn <- h2o.deeplearning(x = 2:ncol(b_train), y = 1, 
          training_frame = b_train, validation_frame = b_valid,
          activation = "Rectifier", hidden = c(200,200), epochs = 100,
          stopping_rounds = 3)
})
```

```{r}
nn_mse <- h2o.mse(nn,train=TRUE,valid=TRUE)
print(nn_mse)
nn_err <- eval(nn,b_train,b_valid)
print(nn_err)
```


